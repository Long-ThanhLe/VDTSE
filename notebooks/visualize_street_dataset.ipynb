{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, cv2, mmcv, torch, cvut\n",
    "\n",
    "from mmdet.datasets import build_dataloader, build_dataset\n",
    "from operator import itemgetter \n",
    "import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln: failed to create symbolic link 'data/datav2': File exists\n",
      "loading annotations into memory...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/annotations/train_night_rain_v2.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3a5bab8dca0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mconfig_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../configs/street/atss_r50_fpn_1x_street_visualize.py\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmmcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataset size:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tank_vdts/lib/python3.7/site-packages/mmdet/datasets/builder.py\u001b[0m in \u001b[0;36mbuild_dataset\u001b[0;34m(cfg, default_args)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concat_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_from_cfg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATASETS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tank_vdts/lib/python3.7/site-packages/mmcv/utils/registry.py\u001b[0m in \u001b[0;36mbuild_from_cfg\u001b[0;34m(cfg, registry, default_args)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdefault_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mobj_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tank_vdts/lib/python3.7/site-packages/mmdet/datasets/custom.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ann_file, pipeline, classes, data_root, img_prefix, seg_prefix, proposal_file, test_mode, filter_empty_gt)\u001b[0m\n\u001b[1;32m     80\u001b[0m                                               self.proposal_file)\n\u001b[1;32m     81\u001b[0m         \u001b[0;31m# load annotations (and proposals)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_infos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_annotations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mann_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;31m# filter data infos if classes are customized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustom_classes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tank_vdts/lib/python3.7/site-packages/mmdet/datasets/coco.py\u001b[0m in \u001b[0;36mload_annotations\u001b[0;34m(self, ann_file)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \"\"\"\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoco\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCOCO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mann_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cat_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat2label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mcat_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tank_vdts/lib/python3.7/site-packages/pycocotools/coco.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, annotation_file)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loading annotations into memory...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotation_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             assert type(\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/annotations/train_night_rain_v2.json'"
     ]
    }
   ],
   "source": [
    "!ln -s /home/member/Workspace/tank/TS_release/dataset/datav2 data\n",
    "# Build dataset\n",
    "config_file = \"../configs/street/atss_r50_fpn_1x_street_visualize.py\"\n",
    "cfg = mmcv.Config.fromfile(config_file)\n",
    "dataset = build_dataset(cfg.data.train)\n",
    "\n",
    "print(\"dataset size:\", len(dataset))\n",
    "classnames = ('background',) + (dataset.CLASSES,)\n",
    "\n",
    "_MEAN = np.array(cfg.img_norm_cfg.mean)\n",
    "_STD = np.array(cfg.img_norm_cfg.std)\n",
    "print('dataset keys: ', dataset.__dict__.keys())\n",
    "print('dataset coco: ', dataset.coco.__dict__.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get a sample\n",
    "idx = 2\n",
    "sample = dataset.__getitem__(idx)\n",
    "print(sample.keys())\n",
    "\n",
    "img_metas = sample['img_metas'].data\n",
    "print(img_metas)\n",
    "print(sample['gt_labels'].data.tolist())\n",
    "labels = itemgetter(*sample['gt_labels'].data)(dataset.CLASSES)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # draw single image\n",
    "# # Get image\n",
    "# # visual lize img by name\n",
    "# name = 'IMG_1360.JPG'\n",
    "# # for key, value in dataset.coco.imgs.items():\n",
    "# #     if value['file_name'] == name:\n",
    "# #         img_id = value['id']\n",
    "# #         print('value is: ',value)\n",
    "# #         break\n",
    "# # print(img_id)\n",
    "# # sample = dataset.__getitem__(img_id)\n",
    "\n",
    "# for i, (key, value) in enumerate(dataset.coco.imgs.items()):\n",
    "#     if value['file_name'] == name:\n",
    "#         img_id = i\n",
    "#         break\n",
    "# print(img_id)\n",
    "# sample = dataset.__getitem__(img_id)\n",
    "# Get a sample\n",
    "idx = 2\n",
    "sample = dataset.__getitem__(idx)\n",
    "imgage = sample['img'].data\n",
    "image = imgage.cpu().numpy().transpose((1,2,0))\n",
    "image = np.clip(image * _STD + _MEAN, 0, 255).astype('uint8')\n",
    "print(image.shape)\n",
    "# image = cv2.rotate(image, cv2.ROTATE_180)\n",
    "# Draw bboxes\n",
    "gt_bboxes = sample['gt_bboxes'].data.numpy()\n",
    "labels_name = itemgetter(*sample['gt_labels'].data)(dataset.CLASSES)\n",
    "image = cvut.draw_bboxes(image, gt_bboxes, labels=sample['gt_labels'].data, classnames=dataset.CLASSES)\n",
    "\n",
    "print(\"Number of bboxes: {}\".format(len(gt_bboxes)))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw whole dataset\n",
    "for idx in range(len(dataset)):\n",
    "    sample = dataset.__getitem__(idx)\n",
    "    # Get image\n",
    "    img = sample['img'].data\n",
    "    image = img.cpu().numpy().transpose((1,2,0))\n",
    "    image = np.clip(image * _STD + _MEAN, 0, 255).astype('uint8')\n",
    "    \n",
    "    # Draw bboxes\n",
    "    gt_bboxes = sample['gt_bboxes'].data.numpy()\n",
    "#     image = cvut.draw_bboxes(image, gt_bboxes)\n",
    "    labels_name = itemgetter(*sample['gt_labels'].data)(dataset.CLASSES)\n",
    "    print(sample['img_metas'].data['filename'])\n",
    "    image = cvut.draw_bboxes(image, gt_bboxes, labels=sample['gt_labels'].data, classnames=dataset.CLASSES)\n",
    "    print(\"Number of bboxes: {}\".format(len(gt_bboxes)))\n",
    "\n",
    "    # # Draw mask\n",
    "    # gt_semsegs = sample['gt_semsegs'].data.numpy()\n",
    "    # gt_semsegs = cv2.resize(gt_semsegs[0], image.shape[:2][::-1])\n",
    "    # image = cvut.draw_masks_overlay(image, [gt_semsegs])\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistics based on dataset\n",
    "num_classes = np.zeros(5, dtype=np.int)\n",
    "for idx in tqdm.tqdm(range(len(dataset))):\n",
    "    sample = dataset.__getitem__(idx)\n",
    "    labels = sample['gt_labels'].data\n",
    "    num_classes[labels] += 1\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistic based on json\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "train_file = '/home/member/Workspace/tank/TS/data/annotations/train.json'\n",
    "test_file = '/home/member/Workspace/tank/TS/data/annotations/test.json'\n",
    "all_ = '/home/member/Workspace/tank/TS/data/annotations/thesis_train.json'\n",
    "\n",
    "with open(train_file) as f:\n",
    "    train_anno = json.load(f)\n",
    "with open(test_file) as f:\n",
    "    test_anno = json.load(f)\n",
    "\n",
    "with open(all_) as f:\n",
    "    all_anno = json.load(f)\n",
    "\n",
    "train_num_elements = np.zeros(5, dtype=np.int)\n",
    "test_num_elements = np.zeros(5, dtype=np.int)\n",
    "all_num_elements = np.zeros(5, dtype=np.int)\n",
    "\n",
    "for an in train_anno['annotations']:\n",
    "    train_num_elements[an['category_id']-1] += 1\n",
    "    \n",
    "for an in test_anno['annotations']:\n",
    "    test_num_elements[an['category_id']-1] += 1\n",
    "\n",
    "for an in all_anno['annotations']:\n",
    "    all_num_elements[an['category_id']-1] += 1\n",
    "\n",
    "print('train: ', train_num_elements)\n",
    "print('test : ', test_num_elements)\n",
    "print('all  : ', all_num_elements)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
